{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "321b9e4d-e0c0-443e-b879-8d5fad25153b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import Dataset, load_dataset\n",
    "from peft import LoraConfig\n",
    "from transformers import (AutoModelForCausalLM, AutoTokenizer,\n",
    "                          BitsAndBytesConfig, TrainingArguments)\n",
    "from trl import SFTTrainer\n",
    "\n",
    "\n",
    "model_path = \"../models/llama3-ko-alwayssaewoo_problem-adapter\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, use_fast=False)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7dec8420-6f3e-4b21-89d0-174a331b7f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_config = BitsAndBytesConfig(\n",
    "    load_in_4bit = True,\n",
    "    bnb_4bit_quant_type = \"nf4\",\n",
    "    bnb_4bit_compute_dtype = torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b8650e6-d9e4-480c-bd86-01d1fe20e05c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60a744fe7543431086ae3e69a2d2b45e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The module name  (originally ) is not a valid Python identifier. Please rename the original module to avoid import issues.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    quantization_config = quant_config\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4118373f-86ba-4aa9-9b57-d7c0dcceb8bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8903898cb4149dfb069c8570a308639",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The module name  (originally ) is not a valid Python identifier. Please rename the original module to avoid import issues.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_path, use_fast=False)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "     model_path,\n",
    "    device_map=\"cuda\",\n",
    "    dtype=\"auto\"\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dfd6059-c4e0-4f43-8afe-9d02c3a89a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir = \"./arg\", # 체크포인트, 로그 저장 경로\n",
    "    save_total_limit = 2, # ./arg 저장 체크포인트 최대 개수\n",
    "        logging_steps = 10, # 로그 출력 간격\n",
    "        num_train_epochs = 3, # 에폭\n",
    "        per_device_train_batch_size = 4, # GPU당 배치 크기\n",
    "        gradient_accumulation_steps = 8, # gradient accumulation (미니 배치 후 업데이트)\n",
    "        learning_rate = 2e-4, # 학습률\n",
    "        save_steps = 50, # 모델 저장 업데이트 간격\n",
    "        fp16 = True, # fp16 설정\n",
    "        eval_strategy = \"no\" # 모델 평가 no\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c329643d-c194-4dbe-915f-1ca1db8c2874",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../problem_data/train.jsonl\"\n",
    "\n",
    "def combine(example):\n",
    "    instruction = example[\"instruction\"]\n",
    "    input_text = example[\"input\"]\n",
    "    output_text = example[\"output\"]\n",
    "    example[\"text\"] = f\"<s>[INST] {instruction} {input_text} [/INST] {output_text}</s>\"\n",
    "    return example\n",
    "\n",
    "dataset = load_dataset(\"json\", data_files=data_path, split=\"train\")\n",
    "dataset = dataset.map(combine)\n",
    "test_data_path = \"../data/test.jsonl\"\n",
    "test_dataset = load_dataset(\"json\", data_files=test_data_path, split=\"train\")\n",
    "test_dataset = test_dataset.map(combine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8e629dc-e22b-4933-82f6-258a2d37ca6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LoRA 세팅\n",
    "lora_config = LoraConfig(\n",
    "    lora_alpha = 16,\n",
    "    lora_dropout = 0.1,\n",
    "    r = 16,\n",
    "    bias = \"none\",\n",
    "    task_type = \"CAUSAL_LM\"\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "660e9f49-0b34-4f18-b42d-68732eaeb9d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/peft/mapping_func.py:72: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/peft/tuners/tuners_utils.py:282: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c52786b0191b464fa82549725389e4a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding EOS to eval dataset:   0%|          | 0/103 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f62d55339724b5b854b04b29d3a2380",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing eval dataset:   0%|          | 0/103 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a854a79ca6684e26b4944d5953a64006",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating eval dataset:   0%|          | 0/103 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset,\n",
    "    eval_dataset=test_dataset,  \n",
    "    peft_config=lora_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1d65afb-8b13-4dab-88d6-294c659ee869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.1008527278900146, 'eval_model_preparation_time': 0.0281, 'eval_runtime': 6.7179, 'eval_samples_per_second': 15.332, 'eval_steps_per_second': 1.935, 'eval_entropy': 1.3970987705083995, 'eval_num_tokens': 0.0, 'eval_mean_token_accuracy': 0.5705152383217444}\n"
     ]
    }
   ],
   "source": [
    "eval_result = trainer.evaluate()\n",
    "print(eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3757af4-face-4f71-ac20-01b52c2a8730",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 입력 ===\n",
      "주어진 주제를 기반으로 주관식 문제를 생성하라.\n",
      "=== 모델 출력 ===\n",
      "주어진 주제를 기반으로 주관식 문제를 생성하라. 주제는 \"가족\"이다. 주관식 문제는 다음과 같은 형태로 작성된다: \"가족은___.\"으로 시작한다. 주관식 문제는 답변자의 개인적인 생각과 감정을 반영하므로, 여러 사람에게 다르게 답할 수 있다. 주제에 대한 주관식 문제를 하나씩 작성해보자.\n",
      "\n",
      "1. 가족은___.\n",
      "2. 가족은___.\n",
      "3. 가족은___.\n",
      "4. 가족은___.\n",
      "5. 가족은___.\n",
      "\n",
      "1. 가족은 나의 삶에 불가결한 존재입니다.\n",
      "2. 가족은 내 인생에서 가장 소중한 재산입니다.\n",
      "3. 가족은 내 삶의 안정과 행복의 근본입니다.\n",
      "4. 가족은 내 인생에서 가장 큰 사랑과 희생을 주는 존재입니다.\n",
      "5. 가족은 내 인생의 가장 큰 보상입니다. \n",
      "\n",
      "이러한 주관식 문제는 다양한 답변을 통해 다양한\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "gen = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "for i in range(1):\n",
    "    prompt = \"주어진 주제를 기반으로 주관식 문제를 생성하라.\"#test_dataset[i][\"instruction\"]\n",
    "    print(\"=== 입력 ===\")\n",
    "    print(prompt)\n",
    "    print(\"=== 모델 출력 ===\")\n",
    "    print(gen(prompt, max_new_tokens=200)[0][\"generated_text\"])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf6ef0c-e12b-48a2-802e-ff668b172ea1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
